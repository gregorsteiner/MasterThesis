
\section{Empirical Strategy}

\subsection{Setting}

We employ an event study design to measure the effect of natural disasters on standardized test outcomes. An event study design is a staggered adoption design where units are first-treated at different points in time, and there may or may not be never-treated units \citep{Sun_2021}.

In order to identify a causal effect, unobservable determinants of a county's test scores must be unrelated to natural disasters conditional on observable characteristics of that county. The occurrence of natural disasters is plausibly random conditional on location. Furthermore conditioning on the year should account for an increasing trend in natural disasters due to climate change. Thus, independence of mean test scores and natural disasters is plausible conditional on county and year fixed effects.

Consequently, the baseline specification is
\begin{align} \label{baseline}
	y_{i, t, g} = \sum_{\tau = -9, \tau \neq -1}^{9} \beta_\tau D_{i, t-\tau} + \alpha_i + \lambda_t + \zeta_g + X_{i, t} \gamma + \varepsilon_{i, t, g} \;,
\end{align}
where $y_{i, t, g}$ is the outcome of interest for county $i$, year $t$, and grade $g$. County, year, and grade fixed-effects are given by $\alpha_i$, $\lambda_t$, and $\zeta_g$ respectively and $X_{i, t}$ is a row vector of additional control variables. $D_{i, t-\tau}$ is a treatment indicator for county $i$ in year $t-\tau$. That is, $D_{i, t-\tau} = 1$ if the county had already experienced a disaster $\tau$ years ago at time $t$. Since we consider the time period 2009-2018, $-9 \leq \tau \leq 9$.

Note that treatment must be absorbing, meaning the sequence $(D_{i, t})_{t=1}^T$ must be a non-decreasing sequence of $0$s and $1$s. In other words, after being treated for the first time a county stays treated. In the present application this means treatment refers to having experienced a disaster rather than experiencing a disaster in that year. This is common practice and does not cause bias due to the conditionally random nature of natural disasters \citep{Deryugina_2017}. Thus, the emphasis lies on cumulative long-term effects rather than instantaneous short-term effects.

It is implausible that the treatment effects are constant in our setting. The extent of disasters varies substantially, and also the level of preparation for such disasters likely displays high variance across counties. 

\subsection{Interaction-weighted estimator}

We utilize the interaction-weighted (IW) estimator proposed by \cite{Sun_2021} that is robust to treatment effects heterogeneity. The main interest lies on the cohort average treatment effect on the treated (CATT),
\begin{align*}
	CATT_{e, \tau} := \E \left[ Y_{i, t+\tau} - Y_{i, t+\tau}^{\infty} | E_i = e \right],
\end{align*}
where $Y_{i, t+\tau}^{\infty}$ is the counterfactual of being never treated and $E_i$ denotes the first treatment period. Thus, $CATT_{e, \tau}$ is the average treatment effect on the treated $\tau$ years after being treated for the first time for the cohort that was first treated in year $e$.

The estimation procedure consists of three main steps:
\begin{enumerate}
	\item Estimate $CATT_{e, \tau}$ using a linear fixed effects specification with interactions between relative period indicators and cohort indicators:
	\begin{align} \label{CATTDID}
		y_{i, t, g} = \sum_{e \notin C}^{}\sum_{\tau \neq -1}^{} \delta_{e, \tau} (\mathds{1}\{E_i = e\} D_{i, t-\tau}) + \alpha_i + \lambda_t + \zeta_g + \varepsilon_{i, t, g} \;,
	\end{align}
	where $C$ is the set of comparison cohorts. In our case $C$ is the never treated cohort, i.e. $C = {\infty}$. If there is a cohort that is always treated, i.e. that already receives treatment in the first period, then we need to exclude this cohort. The coeffiecient estimator $\widehat{\delta}_{e, \tau}$ that we obtain from (\ref{CATTDID}) estimates $CATT_{e, \tau}$.
	
	\item Weight the estimators by the share of the respective cohort in the sample in that period. Let $\hat{W}^\tau$ be a weight matrix with element $(t, e)$
	\begin{align*}
		[\widehat{W}^\tau]_{t, e} := \frac{\mathds{1}\{t - e = \tau\} \sum_{i = 1}^{N} \mathds{1}\{E_i = e\}}{\sum_{e \in h^{\tau}} \sum_{i = 1}^{N} \mathds{1}\{E_i = e\}},
	\end{align*}
	where $h^{\tau} := \{e: 1 - \tau \leq e \leq \max(E_i) - 1 - \tau\}$ is the set of cohorts that experience at least $\tau$ periods of treatment.
	
	\item Take the average over all $CATT_{e, \tau}$ estimates weighted by the cohort shares in the weight matrices. Let $vec(A)$ be the vectorize operator that vectorizes matrix $A$ by stacking its columns and let $\widehat{\delta}$ be the vector that collects $\widehat{\delta}_{e, \tau}$ for all $e$ and $\tau$. Then, the IW estimator $\widehat{v}_g$ for bin $g$ can be written as 
	\begin{align}
		\widehat{v}_g := \frac{1}{|g|} \sum_{\tau \in g} [vec(\widehat{W}^\tau)]^\intercal \widehat{\delta}.
	\end{align}
	For a singleton bin $g = \{\tau\}$, this simplifies to
	\begin{align*}
		\widehat{v}_{g} := [vec(\widehat{W}^\tau)]^\intercal \widehat{\delta}.
	\end{align*}
	
\end{enumerate}

Under some standard assumptions, $\widehat{v}_g$ is asymptotically normal \citep[for a proof and a detailed description of said assumptions see][Appendix C]{Sun_2021}. Under the additional assumptions of parallel trends and no anticipatory behavior, $\widehat{v}_g$ is consistent, that is it converges in probability to
\begin{align*}
	\widehat{v}_g \overset{p}{\to} [vec(W^{\tau})]^\intercal \delta = \sum_{e \in h^{\tau}} \Prob(E_i = e | E_i \in h^{\tau}) CATT_{e, \tau} \; ,
\end{align*}
where $W^{\tau}$ is the probability limit of the weight matrix $\widehat{W}^\tau$.


Under quasi-random treatment assignment, the parallel trends assumption is likely justified \citep{Roth_2022}. 



