
\section{Empirical Strategy} \label{EmpStrat}

\subsection{Setting}

We employ an event study design to measure the effect of natural disasters on standardized test outcomes. An event study design is a staggered adoption design where units are first-treated at different points in time, and there may or may not be never-treated units \citep{Sun_2021}.

Note that treatment must be absorbing, meaning the sequence of treatment indicators $(D_{i, t})_{t=1}^T$ must be a non-decreasing sequence of $0$s and $1$s. In other words, after being treated for the first time a county stays treated. In the present application this means treatment refers to having experienced a disaster rather than experiencing a disaster in that year. While a disaster itself may be transient, the effects caused by the disaster may not be. This is common practice and does not cause bias due to the conditionally random nature of natural disasters \citep{Deryugina_2017}. Thus, the emphasis lies on cumulative long-term effects rather than instantaneous short-term effects.

In order to identify a causal effect, unobservable determinants of a county's test scores must be unrelated to natural disasters conditional on observable characteristics of that county. The occurrence of natural disasters is plausibly random conditional on location. Furthermore conditioning on the year should account for an increasing trend in natural disasters due to climate change. Thus, independence of mean test scores and natural disasters is plausible conditional on county and year fixed effects.

Consequently, the baseline specification is
\begin{align} \label{baseline}
	y_{i, t, g} = \sum_{l = -9}^{8} \beta_l \mathds{1}\{t - E_i = l\} + \alpha_i + \lambda_t + \zeta_g + \varepsilon_{i, t, g} \;,
\end{align}
where $y_{i, t, g}$ is the outcome of interest for county $i$, year $t$, and grade $g$. County, year, and grade fixed-effects are given by $\alpha_i$, $\lambda_t$, and $\zeta_g$ respectively. $E_i$ denotes the first year of treatment and $\mathds{1}\{t - E_i = l\}$ is a treatment indicator for county $i$ $l$ years after initial treatment. That is, it is $1$ if the county had already experienced the first disaster $l$ years ago. The set of counties which experience their first disaster in the same period, i.e. have the same $E_i$, are referred to as a cohort.

Since we consider the time period 2009-2018, $-9 \leq l \leq 9$, but note that $l = 9$ would correspond to a unit that experienced a disaster in the first period and is therefore always treated. As recommended by \cite{Sun_2021} and \cite{Callaway_2021}, these units are dropped from estimation. Neither can treatment effects be identified for that group nor are they useful as a comparison group under standard parallel trends assumptions.

Also, we need to drop at least two leads or lags to avoid a multicollinearity problem. A complete set of treatment leads and lags is perfectly collinear with unit and time fixed-effects \citep[for an extensive discussion of this issue see][section 3.2]{Borusyak_2021}. It is common to drop the first relative indicator prior to treatment (i.e. $\beta_{-1} = 0$). This acts as a normalization of treatment relative to the period before treatment. Furthermore, we bin the distant leads, that is we combine the treatment indicators for $l \leq -5$. This solves the collinearity problem.

Apart from avoiding the collinearity issue, there is also another reason for binning: Distant treatment leads have relatively few observations (see Table \ref{tab:BinSizes}). In other words, few counties are first treated very late and therefore only few counties experience many years before treatment. In that sense, binning increases the sample size on the distant leads. This makes the estimates more precise and more robust to outliers. Thus, equation (\ref{baseline}) turns into
\begin{align} \label{baselineBinned}
	y_{i, t, g} = \beta_{-5}  \mathds{1}\{t - E_i \leq 5\} + \sum_{l = -4, l \neq -1}^{8} \beta_l \mathds{1}\{t - E_i = l\} + \alpha_i + \lambda_t + \zeta_g + \varepsilon_{i, t, g} \;.
\end{align}

\input{BinSizes.tex}

It is implausible that the treatment effects are constant in our setting. The extent of disasters varies substantially, and also the level of preparation for such disasters likely displays high variance across counties. Also, some counties may experience additional natural disasters after the first one, while others only experience one. Naturally, we would expect larger treatment effects for the former group.

With heterogenous treatment effects, standard two-way fixed-effects estimators are inadequate \citep{deChaisemartin_2020, deChaisemartin_2022, Sun_2021}. Therefore, we use an alternative estimation procedure by \cite{Sun_2021}, which will be explained below. A similar estimator was introduced by \cite{Callaway_2021}. However, the latter is unable to handle multiple observations for the same unit-period combination. Since we have multiple grades for each county-year combination this would be a severe restriction in our setting. That is why, \cite{Sun_2021} is better suited.

Treatment adoption varies in time: Counties that are first treated in a given year form a cluster, that is treatment assignment happens in clusters. The results in \cite{Abadie_2017} show that in such settings it is necessary to cluster standard errors at level of treatment assignment. Therefore, standard errors are clustered at the cohort level.



\subsection{Interaction-weighted estimator}

We utilize the interaction-weighted (IW) estimator proposed by \cite{Sun_2021} that is robust to treatment effects heterogeneity. The main interest lies on the cohort average treatment effect on the treated (CATT),
\begin{align*}
	CATT_{e, l} := \E \left[ Y_{i, t+l} - Y_{i, t+l}^{\infty} | E_i = e \right],
\end{align*}
where $Y_{i, t+l}^{\infty}$ is the counterfactual of being never treated and $E_i$ denotes the first treatment period. Thus, $CATT_{e, l}$ is the average treatment effect on the treated $l$ years after being treated for the first time for the cohort that was first treated in year $e$.

The estimation procedure consists of three main steps:
\begin{enumerate}
	\item Estimate $CATT_{e, l}$ using a linear fixed effects specification with interactions between relative period indicators and cohort indicators:
	\begin{align} \label{CATTDID}
		y_{i, t, g} = \sum_{e \notin C}^{}\sum_{l \neq -1}^{} \delta_{e, l} (\mathds{1}\{E_i = e\} \mathds{1}\{t - E_i = l\}) + \alpha_i + \lambda_t + \zeta_g + \varepsilon_{i, t, g} \;,
	\end{align}
	where $C$ is the set of comparison cohorts. In our case $C$ is the never treated cohort, i.e. $C = {\infty}$. If there is a cohort that is always treated, i.e. that already receives treatment in the first period, then we need to exclude this cohort. The coeffiecient estimator $\widehat{\delta}_{e, l}$ that we obtain from (\ref{CATTDID}) estimates $CATT_{e, l}$.
	
	\item Weight the estimators by the share of the respective cohort in the sample in that period. Let $\hat{W}^l$ be a weight matrix with element $(t, e)$
	\begin{align*}
		[\widehat{W}^l]_{t, e} := \frac{\mathds{1}\{t - e = l\} \sum_{i = 1}^{N} \mathds{1}\{E_i = e\}}{\sum_{e \in h^{l}} \sum_{i = 1}^{N} \mathds{1}\{E_i = e\}},
	\end{align*}
	where $h^{l} := \{e: 1 - l \leq e \leq \max(E_i) - 1 - l\}$ is the set of cohorts that experience at least $l$ periods of treatment.
	
	\item Take the average over all $CATT_{e, l}$ estimates weighted by the cohort shares in the weight matrices. Let $vec(A)$ be the vectorize operator that vectorizes matrix $A$ by stacking its columns and let $\widehat{\delta}$ be the vector that collects $\widehat{\delta}_{e, l}$ for all $e$ and $l$. Then, the IW estimator $\widehat{v}_g$ for bin $g$ can be written as 
	\begin{align}
		\widehat{v}_g := \frac{1}{|g|} \sum_{l \in g} [vec(\widehat{W}^l)]^\intercal \widehat{\delta}.
	\end{align}
	For a singleton bin $g = \{l\}$, this simplifies to
	\begin{align*}
		\widehat{v}_{g} := [vec(\widehat{W}^l)]^\intercal \widehat{\delta}.
	\end{align*}
	
\end{enumerate}

Under some standard assumptions, $\widehat{v}_g$ is asymptotically normal \citep[for a proof and a detailed description of said assumptions see][Appendix C]{Sun_2021}. Under the additional assumptions of parallel trends and no anticipatory behavior, $\widehat{v}_g$ is consistent, that is it converges in probability to
\begin{align*}
	\widehat{v}_g \overset{p}{\to} [vec(W^{l})]^\intercal \delta = \sum_{e \in h^{l}} \Prob(E_i = e | E_i \in h^{l}) CATT_{e, l} \; ,
\end{align*}
where $W^{l}$ is the probability limit of the weight matrix $\widehat{W}^l$.

We use $\widehat{v}_g$ as an estimator for $\beta_{g}$ in equation (\ref{baselineBinned}) and we exploit the existing implementation in the \textbf{fixest} R package \citep{Berge_2018}.

\subsection{Identifying assumptions}

Below we discuss the identifying assumptions.

\textbf{Parallel Trends:} Parallel trends in the sense of \cite{Sun_2021} refers to the following: $\E[Y_{i, t}^{\infty} - Y_{i, s}^{\infty} | E_i = e]$ does not depend on $e$ for any $s \neq t$. That is, the expected temporal difference, i.e. the trend, in the potential outcomes of being never-treated is the same for all treatment timings. A conditional version of the assumption, as in \cite{Callaway_2021}, should definitely hold, as test scores and natural disasters are plausibly independent given location. However, we cannot be sure about the unconditional version required by \cite{Sun_2021}.

Testing for parallel trends is problematic for two reasons: These tests tend to have very low power and they introduce selective inference type issues if inference is conditional on passing a parallel trends test \citep{Rambachan_2019}. A purely visual inspection of pre-treatment trends does not indicate a violation of the parallel trends assumption (see appendix \ref{PreTrends}). In fact, the trends look almost identical for treated and control (never-treated) units for most cohorts.

\textbf{No Anticipatory Behavior:} There is no treatment effect prior to treatment, that is $\E[Y_{i, e+l} - Y_{i, e+l}^{\infty}] = 0$ for all $e$ and all $l < 0$. This assumption is plausible as the treatment path is not known. Natural disasters are quasi-random and cannot be reliably forecast more than a few days in advance. Thus, anticipatory behavior is implausible.

Both identifying assumptions should be fulfilled and the IW-Estimator consistently estimates a weighted average of the cohort average treatment effects on the treated.


\subsection{Heat}

For the effect of heat exposure we utilize a different design. A binary treatment indicator is not-well suited to capture the effect of cumulative heat exposure, as heat exposure is continous. Instead, we follow \cite{Goodman_2020} in using the two aforementioned measures: average maximum daily temperature and days above 30°C\footnote{Of course, the threshold of 30°C is somewhat arbitrary. However, changing it slightly does not lead to meaningful differences in the results.}. These give rise to an interesting marginal interpretation: What is the effect of a 1°C hotter school year or of one additional day above 30°C on average test scores?

Again, conditional on location and year heat exposure should be independent of other factors determining academic performance. Also, there is no threat of endogenous selection into test-taking \citep[as in][]{Goodman_2020}, since all students are required to take these standardized tests. Thus, we estimate a simple linear model with county, year, and grade fixed effects,
\begin{align}
	y_{i, t, g} = \beta H_{i, t} + \alpha_i + \lambda_t + \zeta_g + \varepsilon_{i, t, g} \;,
\end{align}
where $H_{i, t}$ is the measure of heat exposure at the county-schoolyear level. Since there are likely no confounding factors, a least squares estimate of $\beta$ can be interpreted causally. A visual analysis of the residuals (available upon request) does not indicate any substantial deviations from a homoskedastic and diagonal covariance matrix. Therefore, we use classical standard errors without any adjustments.







